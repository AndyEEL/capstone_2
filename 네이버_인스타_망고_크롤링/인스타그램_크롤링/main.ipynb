{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "straight-filename",
   "metadata": {},
   "outputs": [],
   "source": [
    "from insta_mainfile import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "remarkable-closing",
   "metadata": {},
   "outputs": [],
   "source": [
    "#URL만 크롤링 하는 부분\n",
    "#바꿀부분: 아이디, 비밀번호, chromedriver 경로"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "minimal-century",
   "metadata": {},
   "outputs": [],
   "source": [
    "userId = \"아이디\"\n",
    "userPw = \"비밀번호\"\n",
    "\n",
    "instaPage = page(\"/Users/gyeonga/Desktop/chromedriver\");\n",
    "instaPage.open('https://www.instagram.com/accounts/login/?next=https://www.instagram.com/&source=mobile_nav');\n",
    "instaPage.login(userId, userPw)\n",
    "instaPage.search(\"인스타푸드\")\n",
    "\n",
    "start = time.localtime()\n",
    "print(\"start time: \", start)\n",
    "driver = instaPage.getDriver()\n",
    "post_list = list_page(driver)\n",
    "post_list.crawling(400)\n",
    "end = time.localtime()\n",
    "print(\"end time: \", end)\n",
    "print()\n",
    "\n",
    "url_list = post_list.get_url_list()\n",
    "print(\"url_list: \")\n",
    "print(url_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "offensive-juvenile",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(url_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "latest-workstation",
   "metadata": {},
   "outputs": [],
   "source": [
    "url_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hollow-guide",
   "metadata": {},
   "source": [
    "-----------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cosmetic-centre",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "import time\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import requests\n",
    "from multiprocessing import Pool\n",
    "import multiprocessing\n",
    "from urllib.request import urlopen, Request\n",
    "from urllib.parse import quote_plus\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "separated-knowing",
   "metadata": {},
   "outputs": [],
   "source": [
    "#URL 한개로 실험, 바꿀 부분 없음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "advised-cocktail",
   "metadata": {},
   "outputs": [],
   "source": [
    "#new_url_list = ['/p/CLy657ulL5q/']\n",
    "new_url_list = url_list[0:300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "animal-pressure",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_url_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "conventional-newark",
   "metadata": {},
   "outputs": [],
   "source": [
    "datas = {\"날짜\":[], \"위치\":[], \"본문\":[], \"댓글수\":[], \"좋아요수\":[], \"해시태그\":[], \"댓글\":[]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "textile-vault",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_infos(url):\n",
    "\n",
    "    full_url = \"https://www.instagram.com\" + url\n",
    "    req = Request(full_url, headers={\"User-Agent\":\"Mozilla/5.0 (Windows NT 6.1; Win64; x64; rv:47.0) Gecko/20100101 Firefox/47.0\"})\n",
    "    webpage = urlopen(req).read()\n",
    "    soup = BeautifulSoup(webpage, \"html.parser\", from_encoding=\"euc-kr\")\n",
    "    print(soup)\n",
    "\n",
    "    try:\n",
    "        js = json.loads(\"\".join(soup.find(\"script\", {\"type\":\"application/ld+json\"}).contents))\n",
    "    except:\n",
    "        js = \"\"\n",
    "    try:\n",
    "        date = js[\"uploadDate\"]\n",
    "    except: \n",
    "        date = \"-\"\n",
    "    try:\n",
    "        location = js[\"contentLocation\"][\"address\"][\"streetAddress\"]\n",
    "    except:\n",
    "        location = \"-\"\n",
    "    try:\n",
    "        body = soup.find(\"meta\", {\"property\":\"og:title\"}).get(\"content\")\n",
    "        body = js[\"caption\"]\n",
    "    except:\n",
    "        body = \"-\"\n",
    "    \n",
    "    try:\n",
    "        numComments = js[\"commentCount\"]\n",
    "    except:\n",
    "        numComments = \"-\"\n",
    "    try:\n",
    "        numLikes = js[\"interactionStatistic\"][\"userInteractionCount\"]\n",
    "    except:\n",
    "        numLikes = \"-\"\n",
    "    \n",
    "    try:\n",
    "        comment = js[\"comment\"]\n",
    "        comment_list = []\n",
    "        for c in comment:\n",
    "            text = c[\"text\"]\n",
    "            person = c[\"author\"][\"alternateName\"]\n",
    "            profile = c[\"author\"][\"mainEntityofPage\"][\"@id\"]\n",
    "        \n",
    "            person_dict = {\"text\": text, \"person\": person, \"profile\":profile}\n",
    "            comment_list.append(person_dict)\n",
    "    except:\n",
    "        comment = \"\"\n",
    "        comment_list = [\"-\"]\n",
    "    \n",
    "    try:\n",
    "        hashtag = soup.find_all(\"meta\", {\"property\": \"instapp:hashtags\"})\n",
    "        hash_list = []\n",
    "        for tag in hashtag:\n",
    "            hash_list.append(tag.get(\"content\"))\n",
    "        videotag = soup.find_all(\"meta\", {\"property\": \"video:tag\"})\n",
    "        for tag in videotag:\n",
    "            hash_list.append(tag.get(\"content\"))\n",
    "    except:\n",
    "        hash_tag = [\"-\"]\n",
    "\n",
    "    datas[\"날짜\"].append(date)\n",
    "    datas[\"위치\"].append(location)\n",
    "    datas[\"본문\"].append(body)\n",
    "    datas[\"좋아요수\"].append(numLikes)\n",
    "    datas[\"댓글수\"].append(numComments)\n",
    "    datas[\"해시태그\"].append(hash_list)\n",
    "    datas[\"댓글\"].append(comment_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "worst-boards",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.localtime()\n",
    "print(\"start time: \", start)\n",
    "for (idx, url) in enumerate(new_url_list):\n",
    "    print(idx)\n",
    "    get_infos(url)\n",
    "end = time.localtime()\n",
    "print(\"end time: \", end)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "comprehensive-ethnic",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(datas)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
